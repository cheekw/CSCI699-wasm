<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <title>OpenCV.js Face Detection</title>
  <link rel="stylesheet" href="./css/style.css">
</head>

<body>
  <div id="info" class="text-center">
    OpenCV.js is loading...
  </div>
  <div id="container">
    <canvas class="center-block" id="canvasOutput" width=320 height=240></canvas>
  </div>
  <div>
    <input type="checkbox" id="face" name="classifier" value="face" checked>
    <label for="face">face</label>
    <input type="checkbox" id="eye" name="cascade" value="eye">
    <label for="eye">eye</label>
  </div>
  <div class="invisible">
    <video id="video" class="hidden">Your browser does not support the video tag.</video>
  </div>
  <script src="./libs/adapter-latest.js"></script>
  <script src="./libs/stats.min.js"></script>
  <script src="./libs/dat.gui.min.js"></script>
  <script src="./libs/utils.js"></script>
  <script>
    var featuresReady = checkFeatures(document.getElementById("info"), { webrtc: true });
  </script>
  <script>
    const preLoadFiles = true;
    const HAAR_CASCADE_FACE_PATH = './data/haarcascade_frontalface_default.xml';
    const HAAR_CASCADE_EYE_PATH = './data/haarcascade_eye.xml';

    const HAAR_CASCADE_FACE_VPATH = './haarcascade_frontalface_default.xml';
    const HAAR_CASCADE_EYE_VPATH = './haarcascade_eye.xml';

    var Module = {
      // https://emscripten.org/docs/api_reference/module.html#Module.preRun
      preRun() {
        if (preLoadFiles) {
          Module.FS_createPreloadedFile(
            '/',
            HAAR_CASCADE_FACE_VPATH,
            HAAR_CASCADE_FACE_PATH,
            true,
            true
          );
          Module.FS_createPreloadedFile(
            '/',
            HAAR_CASCADE_EYE_VPATH,
            HAAR_CASCADE_EYE_PATH,
            true,
            true
          );
        }
      },
      onRuntimeInitialized() {
        const cv = Module;
        let videoWidth, videoHeight;


        let vga = { width: { exact: 512 }, height: { exact: 512 } };

        let resolution = vga;

        // whether streaming video from the camera.
        let streaming = false;

        let video = document.getElementById('video');
        let canvasOutput = document.getElementById('canvasOutput');
        let canvasOutputCtx = canvasOutput.getContext('2d');
        let stream = null;

        let detectFace = document.getElementById('face');
        let detectEye = document.getElementById('eye');

        let info = document.getElementById('info');

        function startCamera() {
          if (streaming) return;
          navigator.mediaDevices.getUserMedia({ video: resolution, audio: false })
            .then(function (s) {
              stream = s;
              video.srcObject = s;
              video.play();
            })
            .catch(function (err) {
              console.log("An error occured! " + err);
            });

          video.addEventListener("canplay", function (ev) {
            if (!streaming) {
              videoWidth = video.videoWidth;
              videoHeight = video.videoHeight;
              video.setAttribute("width", videoWidth);
              video.setAttribute("height", videoHeight);
              canvasOutput.width = videoWidth;
              canvasOutput.height = videoHeight;
              streaming = true;
            }
            startVideoProcessing();
          }, false);
        }

        let faceClassifier = null;
        let eyeClassifier = null;

        let src = null;
        let dstC1 = null;
        let dstC3 = null;
        let dstC4 = null;

        let canvasInput = null;
        let canvasInputCtx = null;

        let canvasBuffer = null;
        let canvasBufferCtx = null;

        function startVideoProcessing() {
          if (!streaming) { console.warn("Please startup your webcam"); return; }
          stopVideoProcessing();
          canvasInput = document.createElement('canvas');
          canvasInput.width = videoWidth;
          canvasInput.height = videoHeight;
          canvasInputCtx = canvasInput.getContext('2d');

          canvasBuffer = document.createElement('canvas');
          canvasBuffer.width = videoWidth;
          canvasBuffer.height = videoHeight;
          canvasBufferCtx = canvasBuffer.getContext('2d');

          srcMat = new cv.Mat(videoHeight, videoWidth, cv.CV_8UC4);
          grayMat = new cv.Mat(videoHeight, videoWidth, cv.CV_8UC1);

          faceClassifier = new cv.CascadeClassifier();
          faceClassifier.load(HAAR_CASCADE_FACE_VPATH);

          eyeClassifier = new cv.CascadeClassifier();
          eyeClassifier.load(HAAR_CASCADE_EYE_VPATH);

          requestAnimationFrame(processVideo);
        }

        function processVideo() {
          stats.begin();
          canvasInputCtx.drawImage(video, 0, 0, videoWidth, videoHeight);
          let imageData = canvasInputCtx.getImageData(0, 0, videoWidth, videoHeight);
          srcMat.data.set(imageData.data);
          cv.cvtColor(srcMat, grayMat, cv.COLOR_RGBA2GRAY);
          let faces = [];
          let eyes = [];
          let size;
          if (detectFace.checked) {
            let faceVect = new cv.RectVector();
            let faceMat = new cv.Mat();
            if (detectEye.checked) {
              cv.pyrDown(grayMat, faceMat);
              size = faceMat.size();
            } else {
              cv.pyrDown(grayMat, faceMat);
              if (videoWidth > 320)
                cv.pyrDown(faceMat, faceMat);
              size = faceMat.size();
            }
            faceClassifier.detectMultiScale(faceMat, faceVect);
            for (let i = 0; i < faceVect.size(); i++) {
              let face = faceVect.get(i);
              faces.push(new cv.Rect(face.x, face.y, face.width, face.height));
              if (detectEye.checked) {
                let eyeVect = new cv.RectVector();
                let eyeMat = faceMat.roi(face);
                eyeClassifier.detectMultiScale(eyeMat, eyeVect);
                for (let i = 0; i < eyeVect.size(); i++) {
                  let eye = eyeVect.get(i);
                  eyes.push(new cv.Rect(face.x + eye.x, face.y + eye.y, eye.width, eye.height));
                }
                eyeMat.delete();
                eyeVect.delete();
              }
            }
            faceMat.delete();
            faceVect.delete();
          } else {
            if (detectEye.checked) {
              let eyeVect = new cv.RectVector();
              let eyeMat = new cv.Mat();
              cv.pyrDown(grayMat, eyeMat);
              size = eyeMat.size();
              eyeClassifier.detectMultiScale(eyeMat, eyeVect);
              for (let i = 0; i < eyeVect.size(); i++) {
                let eye = eyeVect.get(i);
                eyes.push(new cv.Rect(eye.x, eye.y, eye.width, eye.height));
              }
              eyeMat.delete();
              eyeVect.delete();
            }
          }
          canvasOutputCtx.drawImage(canvasInput, 0, 0, videoWidth, videoHeight);
          drawResults(canvasOutputCtx, faces, 'red', size);
          drawResults(canvasOutputCtx, eyes, 'yellow', size);
          stats.end();
          requestAnimationFrame(processVideo);
        }

        function drawResults(ctx, results, color, size) {
          for (let i = 0; i < results.length; ++i) {
            let rect = results[i];
            let xRatio = videoWidth / size.width;
            let yRatio = videoHeight / size.height;
            ctx.lineWidth = 3;
            ctx.strokeStyle = color;
            ctx.strokeRect(rect.x * xRatio, rect.y * yRatio, rect.width * xRatio, rect.height * yRatio);
          }
        }

        function stopVideoProcessing() {
          if (src != null && !src.isDeleted()) src.delete();
          if (dstC1 != null && !dstC1.isDeleted()) dstC1.delete();
          if (dstC3 != null && !dstC3.isDeleted()) dstC3.delete();
          if (dstC4 != null && !dstC4.isDeleted()) dstC4.delete();
        }

        function stopCamera() {
          if (!streaming) return;
          stopVideoProcessing();
          document.getElementById("canvasOutput").getContext("2d").clearRect(0, 0, width, height);
          video.pause();
          video.srcObject = null;
          stream.getVideoTracks()[0].stop();
          streaming = false;
        }

        function initUI() {
          stats = new Stats();
          stats.showPanel(0);
          document.getElementById('container').appendChild(stats.dom);
        }

        function opencvIsReady() {
          console.log('OpenCV.js is ready');
          info.innerHTML = '';
          initUI();
          startCamera();
        }
        opencvIsReady();
      }
    };
  </script>
  <!-- <script async src="./build/asmjs/opencv.js" type="text/javascript"></script> -->
  <!-- <script async src="./build/wasm/opencv.js" type="text/javascript"></script> -->
  <!-- <script async src="./build/wasm-simd/opencv.js" type="text/javascript"></script> -->
  <!-- <script async src="./build/wasm-mt/opencv.js" type="text/javascript"></script> -->
  <script async src="./build/wasm-simd-mt/opencv.js" type="text/javascript"></script>
</body>

</html>